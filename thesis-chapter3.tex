
\chapter{InSAR Background}
\label{CHAP:3}

In this chapter...

%Simons: operating at microwave frequencies, synthetic aper- ture radar (SAR) systems provide unique images representing the electrical and geometrical proper- ties of a surface in nearly all weather conditions. Since they provide their own illumination, SARs can image in daylight or at night. 

%https://www.usgs.gov/observatories/yvo/news/insar-magic-deformation-camera-no-one-saw-coming
%Tracking radars "ping" a target, record the reflected signal, and measure (1) how long it took for the ping's round trip, and (2) the frequency of the return signal. The travel time is a measure of distance to the target. The target's velocity can be determined from the frequency of the return signal, which differs from that of the transmitted signal as a result of the Doppler effect (this is the effect that makes a siren sound different when it is coming toward you versus moving away from you, for example). Air traffic control radars and police speed detectors work on this principle.

\section{Radar Imaging}
\label{CHAP:3-radar}

``Radar'' was originally an acronym for ``RAdio Detection And Ranging'' but it has since become ubiquitous enough enter the common vernacular. Unlike passive sensors that rely on illumination for outside sources, such as optical cameras, a radar is an active sensor that emits its own electromagnetic energy and detects their return. 
This is one of the main advantages of radar, as it allows the sensor to operate equivalently during day or night.
%While certain radars continuously emit energy and listen for the return echoes, in this thesis we consider only pulsed radars.
In general, radars operate at the microwave frequencies (around between 1 GHz and 300 GHz, or wavelengths of 3 m to 1 mm), though the most commonly used frequencies for SAR sensor in earth-observing missions are L-band (wavelengths of $\sim$24 cm), C-band ($\sim$6 cm cm) and X-band ($\sim$3 cm).
Since electromagnetic waves get scattered by objects that are roughly the size of their wavelength, this means that radars are not blocked by water droplets and may see through clouds.
%Although much of the early radar technology development was done for military surveilance purposes


At Goodyear in the 1950s, it was theorized that you could collect the series of energy pulses from a moving radar to form a two-dimensional image. Thus, the radar imaging technique known as synthetic aperture radar (SAR) was developed. 
The first demonstration of a spaceborne earth-observing SAR mission with interferometric capability was Seasat, launched by NASA in 1978
equipped with an L-band radar 
\cite{Born1979SeasatMissionOverview, Gabriel1989MappingSmallElevation}.
Since that time, there have been dozens of mission launched by various space agencies, leading some to call the last decade ``the golden age of SAR'' \citep{Moreira2014GoldenAgeSpaceborne}.

%Synthetic aperture radar (SAR) is a powerful radar imaging technique which works day and night through all weather conditions.



\subsection{Timeline of SAR Constellations}

Figure \ref{fig:ch3-sar-missions} shows a timeline of SAR missions that have been launched by governments and space agencies since 1990. 
During the 90s, the European Space Agency (ESA) launched two C-band SAR satellites: ERS-1 in 1991 and ERS-2 in 1995. The ERS-1 satellite provided the first practical demonstration of spaceborne InSAR's ability to capture surface deformation
when \cite{Massonnet1993DisplacementFieldLanders} mapped the  surface deformationn pattern caused by the 1992 Landers, California earthquake. The first L-band SAR satellite, JERS-1 ,was launched by NASDA\footnote{Although JERS-1 is labeled as a JAXA mission in Figure \ref{fig:ch3-sar-missions}, it was run by NASDA at the time. In 2003, NASDA merged with two other Japanese space agencies, ISAS and NAL, to form JAXA.} in 1992, and the Canadian Space Agency (CSA) launched their own C-band mission, RADARSAT-1, in 1995.


The most influential SAR within the science community has been the Sentinel-1 mission by ESA.
Note that the only ongoing mission providing freely available data is Sentinel-1; however, the future launch of the NISAR ISRO SAR mission (NISAR) will also provide global L-band SAR coverage \citep{Rosen2015NasaIsroSar}.




\begin{figure}
	\centering
	\includegraphics[width=1.1\textwidth]{figures/chapter3-sar/sar-missions.pdf}
	\caption[Timeline of government SAR missions]{Timeline of government-sponsored SAR missions since 1990. Bar lengths indicate life span of mission. Bars which intersect the right edge indicate ongoing missions.
		Colors indicate the space agency operating the mission.
		Missions which provide data free of charge to the general public (as of May 2022) are marked with blue stars.
		Vertical sections of the timeline are divided by the radar frequency of the sensor, showing (from top to bottom) the X-band, C-band, and L-band missions.
		Note that SIR-C/X-SAR and SRTM were equipped with both C- and X-band sensors.}
	\label{fig:ch3-sar-missions}
\end{figure}


In the past four years, the first wave small SAR satellites have been launched by private companies (Figure \ref{fig:ch3-sar-private-const}). Finland's ICEYE was the first company to launch a SAR SmallSat (a satellites weighing under 180 kg) in January 2018, while Capella Space had their first launch in December, 2018. Seven other companies have since launched at least 1 SAR satellite, and in the next five years, there are plans to launch over 500 additional SAR SmallSats \citep{Kulu2021SatelliteConstellations2021}.
While many large SAR constellations expect sub-hourly revisit time for any given point on earth \citep{Stringham2019CapellaXband}, only the large government SAR missions, such as Sentinel-1, ALOS, and NISAR, explicitly plan for consistent global coverage in their mission objectives. However, the possibility of daily or hourly InSAR revisit times opens many new applications previously not possible with the 6-12 day revisit times of large SAR missions  \citep{IceyeAgu2021}(Iceye AGU 2021) \cite{Taylor2021RemoteSensingMountain}.




\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{figures/chapter3-sar/sar-private-constellations.pdf}
	\caption[Private sector SAR constellations]{SAR constellations run by private companies, showing the number of currently launched satellites (blue) stacked under the number of future planned launches (gold). Note the broken y-axis scale, as two companies 
		%	(China Electronics Technology Group and PredaSAR) 
		are planning constellations of 96 satellites.
	}
	\label{fig:ch3-sar-private-const}
\end{figure}



\section{Synthetic Aperture Radar}
\label{CHAP:3-sar}


Synthetic aperture radar is an imaging technique that forms a two-dimensional image representing the electrical and geometrical properties of the scene \cite{Simons2007InterferometricSyntheticAperture}.
%A synthetic aperture radar is a side-looking imaging radar mounting on a moving platform
The imaging geometry for SAR is shown in Figure \ref{fig:ch3-sar-geometry}, which contains a side looking radar on a platform at height $h$ moving in the azimuth directory $x$. 
The radar emits pulses at some frequency (called the \emph{pulse repetition frequency}, or PRF) in the range direction $y$.
%The illuminated portion of the ground has a swath width of $r \lambda / w$
The width of the swath for normal stripmap operation is controlled by the antenna width, $w$, as $r \lambda / w$. Likewise, the size of the illuminated swath in the along track direction is $r \lambda / L$.
The line of sight (LOS) vector is defined as the unit vector pointing from the radar antenna to a point in the illuminated ground swath.


\begin{figure}
	\centering
		\includegraphics[width=0.99\linewidth]{figures/chapter3-sar/ch3-sar-geometry.pdf}
	\caption[Acquisition geometry of an imaging radar]{Acquisition geometry of an  imaging radar. A platform containing a radar instrument is moving with speed $v$ in the azimuth/along-track direction, $x$ at a height $h$.
    The slant range $r$ to the ground point is measured along the line-of-sight (LOS) direction from the antenna to the ground.
   	The radar antenna here has length $L$ (in the azimuth direction) and width $w$.
   	As the radar sends out pulses, each one into an area on the ground called the beam ``footprint'' (oval shape). 
%   	As the platform moves and sends more pulses, they sweep out the radar swath (gray region).
	}
	\label{fig:ch3-sar-geometry}
\end{figure}

% Resolution: shorter pulse better resolution, but also lowers SNR. To get around tradeoff, send long with LFM chip to high snr and fine resolution in range direction
To create a radar image, the energy scattered by points on the ground must be collected and focused in two dimensions. In the range direction,...


$\tau = 37 \mu s$, or about 11 km in length by multiplying by the speed of light.



$$
\phi(t) = \int \omega(t) dt = \int 2 \pi f(t) dt \\
= \int 2 \pi s t + 2 \pi f_c  dt \\
\phi(t) = \pi k t^2 + 2 \pi f_c t + \phi_0
$$
where $k$ is the chirp slope (in Hz / s), $f_c$ is the center frequency of the chirp, and $\phi_0$ (which)

Leave constant $\phi_0 = 0$

Use this phase in a complex exponential:
$$
s(t) = \exp^{j * \phi(t)} \\
= \exp(j (\pi k t^2 + 2 \pi f_c t))
$$
for $t \in (-\tau/2, \tau/2)$.


Figure \ref{fig:ch3-range-compress} demonstrates the effect of bandwidth on range resulting. The real part of an example chirp with parameters matching those of the ERS-1 satellite has an oscillation frequency which increases linearly over time (Figure \ref{fig:ch3-range-compress}a). The chirp has a duration of $\tau \approx 37.12 \mu s$, a chirp slope $k$ of $4 \times 10^{11} Hz / s$, resulting in frequency bandwidth $BW = s \tau$ $\approx$15.5 MHz (Figure \ref{fig:ch3-range-compress}b). By correlating the transmitted chirp with its complex conjugate, we get the impulse response of a point scatter (Figure \ref{fig:ch3-range-compress}c). If a chirp with the same time duration had a smaller slope $s$ (Figure \ref{fig:ch3-range-compress}d), the bandwidth would shrink by the same proportion (Figure \ref{fig:ch3-range-compress}e), and the impulse response would also be more spread out (Figure \ref{fig:ch3-range-compress}f).


\begin{figure}
	\centering
%	\includegraphics[width=0.99\linewidth]{figures/chapter3-sar/ch3-range-compress.pdf}
	\includegraphics[width=0.99\linewidth]{figures/chapter3-sar/radar-chirp-bandwidth-ers.pdf}
%		\includegraphics[width=0.99\linewidth]{figures/chapter3-sar/radar-chirp-bandwidth-ers2.pdf}
	\caption[Range resolution from chirp compression]{
		(a) The real part of a linear frequency-modulated chirp with. a duration of $\tau \approx 37.12 \mu s$, a chirp slope $k$ of $4 \times 10^{11} Hz / s$.
		(b) The magnitude of the Fourier transform of the chirp is approximately a rectangle function with bandwidth $BW = k \tau$ $\approx$15.5 MHz.
		(c) Correlation the transmitted chirp with a replica of the chirp yields the impulse response.
		(d) For a chirp with the same time duration and half of the frequency bandwidth (e), the corresponding impulse response (f) is not as sharp, resulting in a worse range resolution.
	}
	\label{fig:ch3-range-compress}
\end{figure}

The resolution in the azimuth direction is determined by

% in az, res is $r \lambda / l$, real aperture radar. build very big antenna, but infesible for spaceborne. The synthetic aperturre is a processing technique where, for each point on the ground, the refleted radar echoes are collected and focused to a point. Distinguish which echoes are from same point along the flight path by the doppler shift. The has the effect of building up a synthetic aperture equal to (twice?) the length of the swath length.
% The phase history ends up forming a chirp, similar to the range, and can be focues using a matched filter.


%The advantages long wavelengths offer in terms of penetration come with compensating drawbacks. The resolution a sensor depends on the wavelength and on the size of its aperture—the mirror or lens in the case of a camera or a telescope, the antenna in a radar. If you lengthen the wavelength, you increase the size of the aperture you need in order to achieve a given resolution. To produce detailed images with radar requires a very large aperture indeed—far larger than anything a single spacecraft can offer.

%> Synthetic-aperture radar (SAR) provides a way round that problem. Satellites move at quite a clip—typically, in low orbit, around 25,000kph. By taking all the echoes a radar satellite gets from a given target as it passes over it—and processing them into a single image, SAR produces a result as precise as if it had been made using a single aperture as wide across as the distance the satellite travelled while gathering the data—tens of hundreds of kilometres (see diagram).


Processing all echoes during this time results in a fine resolution in the azimuth direction, which is equal to the resulting that would be attainable only by a real aperture of length $2 L_s$ \citep{Cumming2004DigitalProcessingSynthetic}.

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{figures/chapter3-sar/ch3-synth-aper2.pdf}
	\includegraphics[width=0.99\linewidth]{figures/chapter3-sar/ch3-sar-synthetic-aperture.pdf}
	\caption[Concept of the synthetic aperture ]{Concept of the synthetic aperture.
	(Top) One point on the ground is illuminated by a series of pulses. Pictured here are the footprints of the first and last pulses that illuminate the point. 
	(Bottom) Side view of the pulses illuminating the target, forming a synthetic aperture of length $L_s$.
	}
	\label{fig:ch3-synth-aper}
\end{figure}



\section{InSAR Principles}


Possible ways to introduce phase:

- Do the InSAR geometry, get phase measure has diff of 2 phases.
- Fringe frequency, but measure "flat earth", subtract that, leads to topography.
%−2πa + φflat + φtopo + noises

OR
- ...


\begin{figure}[hbt!]
	\centering
	% TODO
	%	\includegraphics[width=0.99\linewidth]{figures/ch3-sar-geometry.pdf}
	\caption{InSAR imaging geometry for topography or deformation mapping.
	}
	\label{fig:ch3-insar-geometry}
\end{figure}




\section{InSAR Noise Sources}
\label{sec:ch3-noise}

The phase of an interferogram can be written as

\citep{Zebker1992DecorrelationInterferometricRadar, Zebker1994AccuracyTopographicMaps, Zebker1997AtmosphericEffectsInterferometric}
\begin{equation}
	\Delta \phi = \frac{4 \pi}{\lambda} \Delta d_{LOS} +  \Delta \phi_{orb} + \Delta \phi_{decor} + \Delta \phi_{unwrap}  + \Delta \phi_{dem} + \Delta \phi_{iono} + \Delta \phi_{tropo}  + \Delta \phi_{n}
\end{equation}
where $ \lambda $ is the radar wavelength and $ \Delta d_{LOS} $ is the surface deformation along the radar LOS direction. The noise terms include orbital errors, phase decorrelation, unwrapping errors, DEM inaccuracies, ionospheric and tropospheric artifacts, and other residual noise terms that are typically an order of magnitude smaller than the error terms listed here.


\subsection{Anatomy of an Interferogram}

While high signal to noise ratio (SNR) interferograms can be analyzed by simply ``counting the fringes'', as is the case for the first published Landers earthquake \cite{Massonnet1993DisplacementFieldLanders}, this is often the exception, rather than the rule.
In many cases, a single interferogram will contain more visual noise features than signals, making it difficult for a non-expert InSAR user to interpret. 

Hawaii example




\begin{figure}[!htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{figures/chapter3-sar/hawaii-example.pdf}
	\caption[Sentinel-1 interferogram over Hawaii showing common noise sources, along with 2018 eruption deformation]{
		(a) Sentinel-1 interferogram from April 20th, 2018 to May 2nd, 2018 over Hawaii, spanning the beginning of the 2018 eruption event.
		Each colored phase cycle of $2\pi$ radians indicates a range change of 2.7 cm along the radar line-of-sight, which can be caused by real surface deformation or a noise source.
		(b) The dense fringes near the coast are caused by turbulent tropospheric noise (see Section \ref{sec:ch3-noise-tropo-strat}).
		(c) Stratified tropospheric noise on the peak of Mauna Kea, the tallest peak on Hawaii at 4,207 m, causes a concentric ring pattern. This pattern is also visible on Mauna Loa in the center of the island, where the phase is strongly correlated with topographic height. See Section \ref{sec:ch3-noise-tropo-strat} for further details.
		(d) An example of decorrelation noise caused by dense tropical rain forests (e) located on windward side of the island.
		(f) Real deformation of $ \sim 40 $cm around the Pu'u '\=O'\=o volcanic cone to the east of K'\=ilauea. In this case, the ground was subsiding down and to the southeast as magma flowed away from Pu'u '\=O'\=o.
		%		The signal of interest in this interferograms, the collapse of the Pu'u '\=O'\=o caldera
		(g) An aerial photo of Pu'u '\=O'\=o shows the caldera collapse on April, 30th, 2018 after magma migrated eastward underground (image source: HVO / USGS).
	}
	\label{fig:sar-hawaii-example}
\end{figure}

Two days after the interferogram on May 4, a  M$_w$ 6.9 earthquake struck the south flank of the Lower East Rift Zone, just south of the zoom.


% at the Sentinel-1  The windward side of the island contains many dense tropical rain forests. These areas show Heavy decorrelation noise at the Sentinel-1 C-band wavelength of 5.5 cm.

%brief fissure eruption occurred on the west flank of the Puʻu ʻŌʻō cone on April 30, 20181. Over the next few days, earthquakes migrated eastward into the LERZ and rift-normal displacements were recorded by GPS instruments, signaling large-scale injection of magma downrift of Puʻu ʻŌʻō. Magma reached the surface in Leilani Estates subdivision on May 3, marking the onset of the LERZ eruption (Fig. 1a)

%1. Table: noise, specific to ifg or SAR, max variance?, common?


%2. Figure: Hawaii, showing Stratified, Turbulence, decorr, defo


%3. ? Figure: unwrap error? DEM error? iono noise? orb ramp?

\subsection{Tropospheric Noise}
\label{sec:ch3-noise-tropo}

%Ideas:
%
%- comparison of ways people have tried to correct for troposphere
%
%- plots/images of possible views into the single day atmosphere.
% -- modis
% -- HRRR, ECMWF
% --  GOES
% -- insar averaging
% 
% axes of comparison:
% - resolution
% - time availability
% - spatial availibility
% - sensitivity to phase propation delay
% 
% 
% SEASONAL plots...
% 

\subsubsection{Turbulent Tropospheric Noise}
\label{sec:ch3-noise-tropo-turb}

\subsubsection{Stratified Tropospheric Noise}
\label{sec:ch3-noise-tropo-strat}


Tropospheric noise in InSAR consists of a stratified component, which correlates with topography \citep{Doin2009CorrectionsStratifiedTropospheric}, and a turbulent component that is random at time scales longer than a day \citep{Emardson2003NeutralAtmosphericDelay, Onn2006ModelingWaterVapor}. Previous studies have made advances in correcting for the stratified component using global atmospheric models \citep{Doin2009CorrectionsStratifiedTropospheric, Jolivet2014ImprovingInsarGeodesy, Cao2021AdvancedInsarTropospheric}, GPS zenith delay measurements \citep{Onn2006ModelingWaterVapor}, external measurements from sensors such as the Moderate Resolution Imaging Spectroradiometer (MODIS) \citep{Li2005InterferometricSyntheticAperture, Barnhart2013CharacterizingEstimatingNoise} or the Medium Resolution Imaging Spectrometer (MERIS)  \citep{Ding2008AtmosphericEffectsInsar}, as well as empirical methods using regressions on InSAR phase and elevation \citep{Zebker2021AccuracyModelFree, Murray2021ClusterBasedEmpirical}.

Early efforts to correct or mitigate the turbulent atmospheric noise used a combination of high pass temporal filtering and low pass spatial filtering \citep{Ferretti2001PermanentScatterersSar, Berardino2002NewAlgorithmSurface}.
%- but as \citep{Liu2012SatelliteRadarInterferometry} notes, gaps in the acquistion, or strong non-Gaussianity from, e.g., severe thunderstorms, break the assumptions of equal variance among APS dates that these filters require.
Several research efforts have attempted to produce estimates of the atmospheric phase delay for each SAR acquisition directly from a time series of interferograms. \citep{Liu2012SatelliteRadarInterferometry} formulated the problem as a linear system using a network of small baseline interferograms. Since the problem of estimating both surface deformation and atmospheric delay is an ill-posed problem given only differential InSAR measurements, the authors assumed zero or known deformation of the study region, and they constrained the estimated troposphere to have zero mean. In an attempt to denoise time series of surface deformation, \citep{Tymofyeyeva2015MitigationAtmosphericPhase} averaged sets of redundant interferograms containing a common reference date, with an assumption of linear or slowly-varying deformation, and subtracted the estimated troposphere.

%  \citep{Havazli2021DetectionThresholdEstimates} almost does what i'm doing (with some type of stratified atmo too), it's just a random multiplier, and it looks like it was almost all simulation
An alternative approach to correcting for the tropospheric turbulence is to treat it as a stochastic noise source in time series analysis \citep{Simons2007InterferometricSyntheticAperture, Agram2015NoiseModelInsar} and estimate its covariance matrix either through auxiliary data sources \citep{Barnhart2013CharacterizingEstimatingNoise, Parker2015SystematicAssessmentAtmospheric} or directly from InSAR data \citep{Lohman2005SomeThoughtsUse}. While these approaches provide a measure of uncertainty in the deformation solution, the uncertainties are given for each pixel (or each model parameter), rather than for each visible deformation feature.




GACOS is an iterative tropospheric decomposition model that integrates global weather models and available GPS zenith delay measurements for estimating tropospheric noise in InSAR data \citep{Yu2018InterferometricSyntheticAperture}. Due to the limited spatial and temporal resolution of weather models and GPS data, GACOS is more effective in removing the stratified tropospheric noise \citep{Doin2009CorrectionsStratifiedTropospheric} than the random turbulent tropospheric noise \citep{Emardson2003NeutralAtmosphericDelay}. 
We found that GACOS does not produce substantial corrections in most Sentinel-1 West Texas interferograms for areas outside the main area of interest (e.g. Figure \ref{fig:GACOS} (a)-(c)). 

\textcolor{red}{Get an interferogram that works, and then show the one that doesn't}

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{paper1-permian/figures/supplement/figureS4-gacos.pdf}		
	\caption[GACOS tropospheric corrections]{(a) LOS measurements (in cm) of a descending interferogram (20150127-20150220) before the GACOS correction. (b) GACOS tropospheric correction (in cm) for the 20150127-20150220 interferogram \citep{Yu2018InterferometricSyntheticAperture}. (c) LOS measurements (in cm) of a descending interferogram (20150127 - 20150220) after the GACOS correction. (d) LOS measurements (in cm) of the 20150127-20150220 interferogram vs. the Digital Elevation Model (DEM).}
	\label{fig:GACOS}
\end{figure}


\section{InSAR Time Series}
\label{sec:ch3-insar-ts}

stacking for avg rate

SBAS linear system. doesn't need to be short baseline. just a way to solve for the phase at each date

Phase linking approaches solve for this using an optimization on each pixels time-covariance matrix.


% Yunjun thesis: the vector of interferometric phase residual that does not fulfill the zero phase closure of interferogram triplets. It includes the decorrelation noise, phase contribution due to the change of dielectric properties of ground scatterers such as soil moisture (De Zan et al., 2014; Morrison et al., 2011), processing inconsistency such as filtering, multilooking, coregistration and interpolation errors (Agram and Simons, 2015; Hanssen, 2001), and/or phase-unwrapping errors.

%An alternative objective function to solve equation (2.1) is minimizing the L2-norm of the residual of phase velocity of adjacent acquisitions (equation (16) in Berardino et al. (2002)). Optimizations with both objective functions give nearly identical solutions for a fully connected network


\subsection{Uncertainty}
\label{sec:ch3-eq-tropo}
Several ways for uncertainty.

jackknife (maybe look into the NSBAS/GIANT time series way they do it....). prob an underestimate, since this is *precision* of the estimator. often it's jsut precision of the noise+deformation phase. but we really want the defo phase.

other is least squares propagation of covariance. difficult to calibrate without good atmo noise estimate, can underestimate/overestimate.

one problem with daily time series: often uncertainty is a single number. but each day's atmo noise can vary by 10-20x.

Even with temporal smoothing (example pic of that super storm cell), there can be many days with "blobs" of atmospheric noise which exceed real deformation.

Chapter (2nd paper) will discus a third novel way using computer vision.


Bootstrap:

From "practictioners guide":
A natural question for the practitioner is to ask  “ Why bootstrap in the linear regression case? Isn ’ t least - squares a well - established approach that  has  served  us  well  in  countless  applications? ”   The  answer  is  that  for  many  problems, least - squares regression has served us well and is always useful as  a first approach but is problematic when the residuals have heavy - tailed distributions or if even just a few outliers are present.

IID assumption: doesn't hold for time series... still gives some estimate. maybe show example of how it overestimates, but that it's not bad because it's mostly accounting for tropo, and not for the phase UQ (cite Zwiebeck paper).


%Problems with pixelwise
%- Image of blob, with 8 mm cutoff, question which part you trust and not
%- Leads into feature-wise uq



\section{InSAR Line-of-sight Decomposition}
\label{sec:ch3-insar-decomp}
An interferogram measures surface deformation between the two SAR acquisition times along the radar line-of-sight (LOS) direction. The LOS deformation, $u_{LOS}$, can be written as: 
\begin{align}
	u_{LOS}= \alpha_{e} u_{e} + \alpha_{n} u_{n} + \alpha_{u} u_{u}
\end{align}
where $u_{e}$, $u_{n}$ and $u_{u}$ are the east, north and up displacements, respectively. The radar look vector $\alpha = [\alpha_e, \alpha_n, \alpha_u]$ can be calculated from the known imaging geometry at every pixel location. This varies significantly across the basin due to the $ \sim$250 km wide Sentinel swath (Figure \ref{fig:los-map}). 


%
%\begin{figure}
%	\centering
%	% TODO
%	%	\includegraphics[width=\textwidth]{}
%	\caption[Line of sight convention]{Line of sight convention used in this thesis for ascending (a) and descending (b) satellite geometries. Vector points from the satellite to the ground}
%	\label{fig:los-asc-desc}
%\end{figure}

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=.98\textwidth]{paper1-permian/figures/supplement/figureS2-los.pdf}
	\caption[East, north, and vertical coefficients of Sentinel-1 LOS vectors]{East, north, and vertical coefficients of the LOS unit vector of all Sentinel-1 path 78 and path 85 pixels. Positive LOS direction points away from the satellite to the ground.}
	\label{fig:los-map}
\end{figure}

In regions where InSAR data are available from two LOS directions, we can decompose the ground motion into its eastward and vertical components.
To perform the decomposition, we first write $u_{asc}$ and $u_{desc}$ in terms of $u_e$, $u_n$ and $u_u$:
\begin{align}
	u_{asc} &= \alpha_{a,e} u_{e} + \alpha_{a,n} u_{n} + \alpha_{a,u} u_{u}\\
	u_{desc} &= \alpha_{d,e} u_{e} + \alpha_{d,n} u_{n} + \alpha_{d,u} u_{u}
\end{align}
We can express $u_e$ and $u_u$ as:
\begin{align}
	u_{e} &\approx  \frac{1}{\beta}  \left[\alpha_{d,u}  u_{asc} - \alpha_{a,u} u_{desc} \right] \\
	u_{u} &\approx  \frac{1}{\beta}  \left[\alpha_{a,e} u_{desc} - \alpha_{d,e}  u_{asc}  \right] 
\end{align}
where  $ \beta = {\alpha_{a,e} \alpha_{d,u}- \alpha_{d,e} \alpha_{a,u}} $.

Because Sentinel-1 satellites are operating in a near-polar orbit, the north look coefficients $\alpha_{a,n}$ and $\alpha_{d,n}$ are both relatively small. Ignoring 1 cm northward motion in $u_n$ only leads to $\sim$ 0.1-0.2 mm error in $u_e$ and $\sim$ 1 mm error in $u_u$ at most locations. \cite{Kim2018AssociationLocalizedGeohazards} detected several localized deformation features within the Delaware Basin related to wastewater injection, CO2 injection, and hydrocarbon production using Sentinel-1 InSAR data.  Our LOS decomposition results are consistent with their study at these locations. For example, in a 12 km x 12 km region centered on a wastewater injection well, we observed $\sim$ 5.5 cm of uplift and $\sim$1.2 cm of east-west motion between November 2014 and April 2017 (Figure \ref{fig:injection-kim-lu}). 



\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{paper1-permian/figures/supplement/figureS3-injection-kim-lu.pdf}
	\caption[Vertical and horizontal deformation near Winkler County, TX]{Cumulative surface deformation between November 2014 and April 2017 due to wastewater injection in Winkler County, TX. The horizontal motion here is $\sim$ 20\% of the vertical motion, with up to $\sim$ 5.5 cm of uplift and $\sim$ 1.2 cm of east-west motion. This localized deformation feature was originally reported in \cite{Kim2018AssociationLocalizedGeohazards}.}
	\label{fig:injection-kim-lu}
\end{figure}




\subsection{Uncertainty Propagation through LOS decomposition}
\label{sec:ch3-decomp-uq-prop}
Since the LOS decomposition is a linear operation, given two LOS uncertainties, we can use linear uncertainty propagation theory to determine the vertical/horizontal uncertainties.

TODO: move this to appendix or not?


